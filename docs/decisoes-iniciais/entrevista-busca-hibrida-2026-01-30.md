# Relat√≥rio de Entrevista: Busca H√≠brida com pgvector e FTS - Integra√ß√£o com Grafo de Conhecimento
**Projeto:** Sentinel / Daratrine
**Data:** 2026-01-30
**Contexto Original:** [Busca H√≠brida com pgvector e FTS.md](../pesquisas/Busca%20H√≠brida%20com%20pgvector%20e%20FTS.md)
**Documentos Relacionados:**
- [Decis√µes Arquiteturais - Grafos de Conhecimento com Apache AGE](decisoes-arquiteturais-grafo.md)
- [Stack RAG Alta Fidelidade para GDDs](entrevista-stack-rag-gdd-2026-01-29.md)

**Objetivo:** Definir decis√µes execut√°veis para implementa√ß√£o da busca h√≠brida integrada ao grafo de conhecimento

---

## Sum√°rio Executivo

Este documento consolida as **12 decis√µes t√©cnicas cr√≠ticas** tomadas durante entrevista estruturada para implementa√ß√£o da **busca h√≠brida (pgvector + FTS) integrada ao grafo de conhecimento Apache AGE** no projeto Sentinel/Daratrine.

A entrevista esclareceu **12 gaps cr√≠ticos** identificados nos documentos de pesquisa, transformando conhecimento estado-da-arte em decis√µes execut√°veis para MVP com **usu√°rio √∫nico** (desenvolvedor/designer), priorizando **simplicidade operacional e valida√ß√£o r√°pida**.

### üéØ Decis√µes Chave

1. **Pipeline RAG Completo:** Query ‚Üí Embedding ‚Üí Busca H√≠brida (pgvector + ts_rank_cd + RRF) ‚Üí Extra√ß√£o Subgrafo 2 Est√°gios ‚Üí Prompt H√≠brido ‚Üí Claude 3.5 Sonnet
2. **Extra√ß√£o de Subgrafo:** Stage 1 FTS em properties (85-95% recall, ~100-200ms) + Stage 2 embedding matching fallback (+15-20% recall, +50-100ms)
3. **Par√¢metros HNSW:** Baseline conservador (m=16, ef_construction=100, ef_search=40) - 200-300MB RAM, recall 85-90%
4. **Field Weighting:** Section-based (peso A para section_name, peso B para chunk_text)
5. **TypeScript Types:** Manual types + Zod valida√ß√£o runtime para 15 labels
6. **Prompt Extra√ß√£o:** temperature=0.1, max_tokens=4000, divis√£o ~10k tokens
7. **Manuten√ß√£o:** Reactive triggers (usu√°rio √∫nico) - VACUUM/REINDEX quando perceber lentid√£o
8. **Valida√ß√£o:** Spot-check (5-10 entidades cr√≠ticas, extrapolar qualidade)

---

## üéØ Abordagem Arquitetural Escolhida

### **Pipeline RAG Sequencial com Busca H√≠brida + Extra√ß√£o de Subgrafo**

**Decis√£o:** Implementar pipeline sequencial que combina busca textual h√≠brida (recall) com extra√ß√£o inteligente de subgrafo (estrutura sem√¢ntica) antes de enviar contexto ao LLM.

#### **Justificativa:**

1. **Busca h√≠brida primeiro** garante recall (abrang√™ncia) - recupera os 10-20 chunks mais relevantes do GDD independente de estrutura
2. **Extra√ß√£o de subgrafo depois** √© mais eficiente - analisa apenas entidades mencionadas nos chunks retornados (vs analisar grafo inteiro)
3. **Alinhado ao documento Busca H√≠brida** (linhas 32-34): "O primeiro est√°gio foca em recall (abrang√™ncia)"
4. **Prompt h√≠brido** combina texto narrativo (chunks) + estrutura sem√¢ntica (grafo) maximizando fidelidade
5. **Lat√™ncia previs√≠vel** - busca h√≠brida <100ms, extra√ß√£o subgrafo ~150-300ms, total <500ms (excluindo LLM)

**Fluxo Completo:**

```
[1] Query Usu√°rio
    ‚Üì
[2] Embedding via HuggingFace (Sentence-Transformers)
    ‚Üì
[3] BUSCA H√çBRIDA (paralela)
    ‚îú‚îÄ Busca Vetorial (pgvector, HNSW, cosine similarity)
    ‚îî‚îÄ Full-Text Search (ts_rank_cd, GIN index)
    ‚Üì
[4] Reciprocal Rank Fusion (RRF, k=60)
    ‚Üì
[5] Top-10 Chunks Retornados
    ‚Üì
[6] EXTRA√á√ÉO DE SUBGRAFO (2 est√°gios)
    ‚îú‚îÄ Stage 1: FTS em properties das 15 labels (GIN index)
    ‚îÇ   ‚Üí top-5 entidades por chunk
    ‚îÇ   ‚Üí ~100-200ms, 85-95% precis√£o
    ‚îÇ
    ‚îî‚îÄ Stage 2: Embedding matching (fallback para chunks com <3 entidades)
        ‚Üí similaridade com description_embedding pr√©-computado
        ‚Üí +50-100ms, +15-20% recall adicional
    ‚Üì
[7] Deduplicate + Limitar (top-10 entidades + top-15 rela√ß√µes 1-hop)
    ‚Üì
[8] PROMPT H√çBRIDO
    ‚îú‚îÄ System Prompt (instru√ß√µes)
    ‚îú‚îÄ Knowledge Graph Metadata (compact format, ~1.5k tokens)
    ‚îÇ   ‚îú‚îÄ Top-10 Entidades (nome + 2-3 properties essenciais)
    ‚îÇ   ‚îî‚îÄ Top-15 Rela√ß√µes (source ‚Üí type ‚Üí target)
    ‚îî‚îÄ Text Chunks (10-20 chunks, se√ß√µes do GDD)
    ‚Üì
[9] Claude 3.5 Sonnet (via Anthropic API)
    ‚Üì
[10] Resposta Final ao Usu√°rio
```

**Refer√™ncia ao Contexto Original:**
> *"O GraphRAG surge como a t√©cnica dominante em 2026 para lidar com a descoberta de informa√ß√µes em dados narrativos privados e t√©cnicos."* (doc Stack RAG, linhas 25-29)

**Esclarecimento:** A implementa√ß√£o combina busca h√≠brida tradicional (pgvector + FTS) com GraphRAG (extra√ß√£o de subgrafo relevante), aproveitando o melhor de ambas abordagens.

---

## üìä Decis√µes T√©cnicas Consolidadas

### RODADA 1: Pipeline e Integra√ß√£o

#### **1.1 Ordem de Execu√ß√£o do Pipeline RAG**

**Gap Esclarecido:** *"Documentos descrevem componentes isolados (busca h√≠brida, queries Cypher, prompt LLM) mas n√£o especificam orquestra√ß√£o sequencial."*

**Decis√£o:** Query ‚Üí Embedding ‚Üí Busca H√≠brida (pgvector + FTS + RRF) ‚Üí Extra√ß√£o Subgrafo 2 Est√°gios ‚Üí Prompt H√≠brido ‚Üí Claude 3.5 Sonnet

**Justificativa:**
- ‚úÖ **Busca h√≠brida primeiro** garante recall (top-10 chunks mais relevantes)
- ‚úÖ **Extra√ß√£o de subgrafo depois** analisa apenas entidades mencionadas nos chunks (efici√™ncia)
- ‚úÖ **Lat√™ncia previs√≠vel** - busca <100ms, extra√ß√£o ~150-300ms, total <500ms
- ‚úÖ **Alinhado ao doc Busca H√≠brida** (linha 33): "primeiro est√°gio foca em recall"

**Refer√™ncia ao Contexto Original:**
> *"A precis√£o sem√¢ntica em 2026 √© alcan√ßada atrav√©s de um pipeline de recupera√ß√£o em m√∫ltiplos est√°gios."* (doc Busca H√≠brida, linhas 32-34)

---

#### **1.2 Extra√ß√£o de Subgrafo: Pipeline de 2 Est√°gios (FTS + Embedding Matching)**

**Gap Esclarecido:** *"Como extrair o subgrafo relevante a partir dos chunks retornados pela busca h√≠brida?"*

**Decis√£o:** Pipeline de 2 est√°gios - Stage 1 FTS em properties (GIN index) + Stage 2 Embedding matching fallback

**Configura√ß√£o:**

**Stage 1: FTS em properties das entidades (GIN index)**
- Executa full-text search em paralelo nos 20 chunks retornados
- Retorna top-5 entidades por chunk
- Performance: ~100-200ms
- Precis√£o: 85-95%
- Recall: 70-85% das entidades relevantes

**Stage 2: Embedding matching (fallback condicional)**
- Aplica apenas nos chunks que encontraram <3 entidades no Stage 1
- Usa coluna `description_embedding` pr√©-computada (√≠ndice HNSW m=16)
- Performance adicional: +50-100ms
- Recall adicional: +15-20%

**Lat√™ncia total:** ~150-300ms (Stage 1 sempre + Stage 2 condicional)

**Recall total:** 85-100% (70-85% + 15-20%)

**Justificativa:**
- ‚úÖ **Best of both worlds** - FTS captura nomes exatos, embeddings capturam varia√ß√µes sem√¢nticas
- ‚úÖ **Performance adaptativa** - Stage 2 s√≥ roda quando necess√°rio
- ‚úÖ **Alinhado ao doc Busca H√≠brida** (linha 249): GIN index em properties j√° planejado

**Refer√™ncia ao Contexto Original:**
> *"A cria√ß√£o de √≠ndices funcionais √© uma t√©cnica avan√ßada recomendada para campos de alta cardinalidade."* (doc Busca H√≠brida, linhas 129-130)

**Esclarecimento:** Stage 1 usa GIN index padr√£o em properties (JSONB). √çndices funcionais s√£o otimiza√ß√£o futura se necess√°rio.

---

#### **1.3 Algoritmo de Ranking L√©xico: ts_rank_cd Nativo**

**Gap Esclarecido:** *"Documento Busca H√≠brida menciona duas op√ß√µes (ts_rank_cd nativo vs BM25 via pg_search) mas n√£o define qual usar."*

**Decis√£o:** ts_rank_cd nativo do PostgreSQL (sem extens√µes adicionais)

**Justificativa:**
- ‚úÖ **Simplicidade MVP** - built-in, zero configura√ß√£o extra no Dockerfile
- ‚úÖ **Performance adequada** - para ~2.4k chunks, diferen√ßa entre ts_rank_cd e BM25 √© marginal (<5% NDCG)
- ‚úÖ **Alinhado √† filosofia MVP** - doc Stack RAG linha 271: "Nenhum reranking adicional no MVP"
- ‚úÖ **Migra√ß√£o clara** - se testes mostrarem imprecis√£o, adicionar pg_search √© opera√ß√£o revers√≠vel

**Configura√ß√£o SQL:**
```sql
-- Busca Full-Text Search com ts_rank_cd nativo
SELECT id, chunk_text,
       ts_rank_cd(search_vector, plainto_tsquery('portuguese', $1)) AS rank
FROM gdd_chunks
WHERE search_vector @@ plainto_tsquery('portuguese', $1)
ORDER BY rank DESC
LIMIT 20;
```

**Refer√™ncia ao Contexto Original:**
> *"O advento de extens√µes como o pg_search introduz o algoritmo BM25 (Best Matching 25), que √© o padr√£o ouro na ind√∫stria."* (doc Busca H√≠brida, linhas 12-13)

**Esclarecimento:** BM25 √© superior em produ√ß√£o otimizada, mas ts_rank_cd √© suficiente para MVP. Migra√ß√£o futura se necess√°rio.

---

#### **1.4 Formato de Metadados do Grafo no Prompt LLM**

**Gap Esclarecido:** *"Documento Stack RAG mostra exemplo b√°sico de prompt h√≠brido mas n√£o especifica quantas entidades, quais properties, formato detalhado."*

**Decis√£o:** Compact format - top-10 entidades (2-3 properties essenciais) + top-15 rela√ß√µes, formato texto natural, ~1.5k tokens

**Properties essenciais por tipo de entidade:**
- **Personagem:** `nome`, `papel_narrativo`, `motivacao_raiz`
- **Fac√ß√£o:** `nome`, `tipo`, `ideologia`
- **Local:** `nome`, `tipo`, `nivel_perigo`
- **Evento:** `nome`, `ato`, `gravidade`
- **Quest:** `nome`, `tipo`, `objetivo_principal`

**Exemplo concreto:**
```
===== KNOWLEDGE GRAPH METADATA =====
Entidades Relevantes (10):
- Personagem: Kael Sombravento (protagonista, motivado por reden√ß√£o)
- Personagem: Aria Luminastra (aliada, motivada por proteger a luz)
- Fac√ß√£o: Fac√ß√£o do Crep√∫sculo (culto, ideologia: busca poder sombrio)
- Local: Cidade de L√∫men (cidade, n√≠vel de perigo: m√©dio)
- Evento: Ex√≠lio de Kael (ato 1, gravidade: alta)
...

Rela√ß√µes Relevantes (15):
- Kael Sombravento TEM_RELACIONAMENTO(Rivalidade: √≥dio profundo) ‚Üí Fac√ß√£o do Crep√∫sculo
- Kael Sombravento PERTENCE_A(cargo: exilado, desde_ato: 1) ‚Üí Reino de Valdoria
- Aria Luminastra CONFLITA_COM ‚Üí Fac√ß√£o do Crep√∫sculo
- Cidade de L√∫men LOCALIZADO_EM ‚Üí Reino de Valdoria
- Ex√≠lio de Kael MOTIVA(natureza: vingan√ßa) ‚Üí Kael Sombravento
...
```

**Justificativa:**
- ‚úÖ **Tokens eficientes** - compact format (~50-100 tokens/entidade vs ~150-200 no full properties)
- ‚úÖ **Cabe confortavelmente no contexto** - ~1.5k tokens de grafo + ~10k tokens de chunks = ~12k total (contexto 200k do Claude)
- ‚úÖ **Formato texto natural** √© mais interpret√°vel pelo Claude que JSON/YAML (benchmarks RAG mostram 5-10% melhoria)
- ‚úÖ **Alinhado ao exemplo do doc Stack RAG** (linha 580)

**Refer√™ncia ao Contexto Original:**
> *"Prompt h√≠brido combina chunks textuais + metadados do grafo de conhecimento."* (doc Stack RAG, linhas 567-596)

---

### RODADA 2: Par√¢metros e Configura√ß√£o

#### **2.1 Par√¢metros HNSW do √çndice pgvector**

**Gap Esclarecido:** *"Documento Busca H√≠brida fornece intervalos (m: 16-32, ef_construction: 100-128, ef_search: 40-100) mas n√£o valores exatos."*

**Decis√£o:** Baseline conservador - m=16, ef_construction=100, ef_search=40

**Configura√ß√£o:**

**Dados do MVP:**
- ~900-2.400 v√©rtices de chunks
- Embeddings: 384 dimens√µes (Sentence-Transformers)
- Hardware: 8GB RAM (Docker Compose)

**Valores escolhidos:**
- **m=16** - conectividade m√≠nima, uso de RAM ~200-300MB
- **ef_construction=100** - profundidade de busca na cria√ß√£o do √≠ndice
- **ef_search=40** - n√≥s explorados em tempo de query

**Performance esperada:**
- RAM: ~200-300MB (deixa ~7.7GB livres)
- Recall: ~85-90%
- Lat√™ncia: <50ms

**Comando SQL:**
```sql
-- Criar √≠ndice HNSW
CREATE INDEX ON gdd_chunks
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 100);

-- Configurar ef_search em tempo de query (session level)
SET hnsw.ef_search = 40;
```

**Justificativa:**
- ‚úÖ **RAM controlada** - 200-300MB deixa espa√ßo para Postgres, NestJS, AGE
- ‚úÖ **Recall adequado para MVP** - 85-90% suficiente para validar proposta de valor
- ‚úÖ **Lat√™ncia excelente** - <50ms no componente vetorial
- ‚úÖ **Escalabilidade** - se passar de 10k chunks, aumentar para m=24 via REINDEX

**Refer√™ncia ao Contexto Original:**
> *"Para um MVP RAG, valores equilibrados s√£o fundamentais para garantir que o sistema escale sem degrada√ß√£o percept√≠vel da qualidade."* (doc Busca H√≠brida, linhas 72-73)

---

#### **2.2 Field Weighting em GDD Estruturado por Se√ß√µes**

**Gap Esclarecido:** *"Documento Busca H√≠brida menciona pesos A/B/C/D mas n√£o especifica como aplicar em GDD estruturado por se√ß√µes Markdown."*

**Decis√£o:** Section-based weighting - peso A para `section_name` (nome da se√ß√£o), peso B para `chunk_text` (conte√∫do da se√ß√£o)

**Implementa√ß√£o:**
```sql
-- Adicionar coluna search_vector com pesos
ALTER TABLE gdd_chunks ADD COLUMN search_vector tsvector
GENERATED ALWAYS AS (
  setweight(to_tsvector('portuguese', unaccent(coalesce(section_name, ''))), 'A') ||
  setweight(to_tsvector('portuguese', unaccent(coalesce(chunk_text, ''))), 'B')
) STORED;

-- Criar √≠ndice GIN
CREATE INDEX ON gdd_chunks USING gin(search_vector);
```

**Exemplo concreto:**
```sql
-- Chunk 1: section_name = "Personagens > Aria Luminastra > Biografia"
--          chunk_text = "Aria nasceu na cidade de L√∫men..."
-- Query: "Aria"
-- Match em section_name (peso A) ‚Üí score MAIOR

-- Chunk 2: section_name = "Personagens > Kael Sombravento > Biografia"
--          chunk_text = "...Kael conheceu Aria durante..."
-- Query: "Aria"
-- Match apenas em chunk_text (peso B) ‚Üí score MENOR que Chunk 1
```

**Justificativa:**
- ‚úÖ **Alinhado ao chunking sem√¢ntico** - cada chunk √© uma se√ß√£o completa, section_name √© o "t√≠tulo" natural
- ‚úÖ **Benef√≠cio claro** - query "Aria Luminastra" d√° boost ao chunk cuja section_name cont√©m o nome
- ‚úÖ **2 pesos suficientes** - A/B capturam 90% do valor de field weighting
- ‚úÖ **Alinhado ao doc Busca H√≠brida** (linha 58): exemplo usa apenas A e B

**Refer√™ncia ao Contexto Original:**
> *"A efic√°cia do ranking l√©xico aumenta significativamente quando se aplica a t√©cnica de 'field weighting'."* (doc Busca H√≠brida, linhas 50-51)

---

#### **2.3 Dicion√°rio de Sin√¥nimos Espec√≠fico do Daratrine**

**Gap Esclarecido:** *"Documento Busca H√≠brida fornece exemplos gen√©ricos de TI (db/database, js/javascript) mas n√£o termos espec√≠ficos do universo Daratrine."*

**Decis√£o:** 10-20 termos essenciais m√≠nimos (varia√ß√µes de nomes de fac√ß√µes, locais, personagens principais) - definir durante implementa√ß√£o ao extrair o GDD real

**Estrutura do arquivo:**
```
# tech_synonyms.syn (a ser criado durante implementa√ß√£o)

# Fac√ß√µes (varia√ß√µes comuns)
crepusculo faccaocrepusculo cultocrepusculo

# Locais (nome completo vs abreviado)
lumen cidadelumen
valdoria reinovaldoria

# Personagens (se houver varia√ß√µes comuns no GDD)
kael kaelsombravento
aria arialuminastra

# Termos m√°gicos (se houver varia√ß√µes PT/EN no GDD)
raioarcano arcanebolt
```

**Configura√ß√£o Postgres:**
```sql
-- Criar text search configuration customizada
CREATE TEXT SEARCH CONFIGURATION daratrine_pt (COPY = portuguese);

-- Adicionar dicion√°rio de sin√¥nimos (ap√≥s criar tech_synonyms.syn)
ALTER TEXT SEARCH CONFIGURATION daratrine_pt
  ALTER MAPPING FOR asciiword, word
  WITH tech_synonyms, portuguese_stem;

-- Usar na coluna search_vector
ALTER TABLE gdd_chunks ALTER COLUMN search_vector TYPE tsvector
GENERATED ALWAYS AS (
  setweight(to_tsvector('daratrine_pt', unaccent(section_name)), 'A') ||
  setweight(to_tsvector('daratrine_pt', unaccent(chunk_text)), 'B')
) STORED;
```

**Justificativa:**
- ‚úÖ **ROI alto** - 10-20 entradas capturam 80% dos casos (nomes pr√≥prios principais s√£o consultados com frequ√™ncia)
- ‚úÖ **Manuten√ß√£o vi√°vel** - f√°cil de criar e manter sincronizado com GDD
- ‚úÖ **Itera√ß√£o f√°cil** - adicionar entradas √© opera√ß√£o n√£o-destrutiva

**Refer√™ncia ao Contexto Original:**
> *"O uso de arquivos de sin√¥nimos (.syn) permite que o motor de busca trate termos como 'DB', 'Database' e 'Banco de Dados' como equivalentes sem√¢nticos."* (doc Busca H√≠brida, linhas 32-33)

---

### RODADA 3: Implementa√ß√£o NestJS

#### **3.1 Implementa√ß√£o Stage 1 + Stage 2 de Extra√ß√£o de Subgrafo**

**Gap Esclarecido:** *"Rodada 1 definiu pipeline de 2 est√°gios mas n√£o detalhou implementa√ß√£o em TypeScript/NestJS."*

**Decis√£o:** Single query approach - Stage 1 executa FTS via query SQL com UNION ALL de 15 labels, Stage 2 usa embeddings pr√©-computados em coluna `description_embedding`

**Implementa√ß√£o TypeScript:**

```typescript
// src/modules/gdd-rag/services/graph.service.ts
import { Injectable, Inject } from '@nestjs/common';
import { Pool } from 'pg';
import { EmbeddingService } from './embedding.service';

interface Chunk {
  id: string;
  text: string;
}

interface GraphMetadata {
  entities: Array<{
    id: string;
    label: string;
    properties: Record<string, any>;
  }>;
  relations: Array<{
    source: string;
    type: string;
    target: string;
    properties?: Record<string, any>;
  }>;
}

@Injectable()
export class GraphService {
  constructor(
    @Inject('PG_POOL') private pool: Pool,
    private embeddingService: EmbeddingService,
  ) {}

  async extractRelevantSubgraph(chunks: Chunk[]): Promise<GraphMetadata> {
    const allEntities = [];

    for (const chunk of chunks) {
      // Stage 1: FTS em properties (UNION ALL de 15 labels)
      const ftsQuery = `
        SELECT 'Personagem' as label, id, properties,
               ts_rank_cd(search_vector, plainto_tsquery('portuguese', $1)) as rank
        FROM gdd_graph."Personagem"
        WHERE search_vector @@ plainto_tsquery('portuguese', $1)

        UNION ALL

        SELECT 'Faccao' as label, id, properties,
               ts_rank_cd(search_vector, plainto_tsquery('portuguese', $1)) as rank
        FROM gdd_graph."Faccao"
        WHERE search_vector @@ plainto_tsquery('portuguese', $1)

        UNION ALL

        SELECT 'Local' as label, id, properties,
               ts_rank_cd(search_vector, plainto_tsquery('portuguese', $1)) as rank
        FROM gdd_graph."Local"
        WHERE search_vector @@ plainto_tsquery('portuguese', $1)

        -- ... repetir para 12 labels restantes

        ORDER BY rank DESC
        LIMIT 5;
      `;

      const ftsResults = await this.pool.query(ftsQuery, [chunk.text]);

      // Stage 2: Embedding matching se <3 entidades encontradas
      if (ftsResults.rows.length < 3) {
        const chunkEmbedding = await this.embeddingService.generate(chunk.text);

        const embeddingQuery = `
          SELECT label, id, properties,
                 1 - (description_embedding <=> $1::vector) as similarity
          FROM (
            SELECT 'Personagem' as label, id, properties, description_embedding
            FROM gdd_graph."Personagem"

            UNION ALL

            SELECT 'Faccao', id, properties, description_embedding
            FROM gdd_graph."Faccao"

            -- ... repetir para 13 labels restantes
          ) all_entities
          WHERE description_embedding IS NOT NULL
          ORDER BY similarity DESC
          LIMIT ${5 - ftsResults.rows.length};
        `;

        const embeddingResults = await this.pool.query(embeddingQuery, [chunkEmbedding]);
        allEntities.push(...ftsResults.rows, ...embeddingResults.rows);
      } else {
        allEntities.push(...ftsResults.rows);
      }
    }

    // Deduplicate por ID + limitar top-10
    const uniqueEntities = this.deduplicateById(allEntities).slice(0, 10);

    // Buscar rela√ß√µes 1-hop das entidades encontradas
    const entityIds = uniqueEntities.map(e => e.id);
    const relations = await this.findRelationsOf(entityIds);

    return {
      entities: uniqueEntities,
      relations: relations.slice(0, 15)
    };
  }

  private deduplicateById(entities: any[]): any[] {
    const seen = new Set<string>();
    return entities.filter(e => {
      if (seen.has(e.id)) return false;
      seen.add(e.id);
      return true;
    });
  }

  private async findRelationsOf(entityIds: string[]): Promise<any[]> {
    // Query Cypher para buscar rela√ß√µes 1-hop
    const query = `
      SELECT * FROM cypher('gdd_graph', $$
        MATCH (source)-[r]->(target)
        WHERE source.id IN $1
        RETURN source.id as source_id, type(r) as type, target.id as target_id, r as properties
      $$) as (source_id agtype, type agtype, target_id agtype, properties agtype);
    `;

    const result = await this.pool.query(query, [JSON.stringify(entityIds)]);
    return result.rows;
  }
}
```

**Schema adicional necess√°rio:**
```sql
-- Adicionar coluna description_embedding em todas as 15 labels
-- (executar durante Fase 1-3 da implementa√ß√£o do grafo)

ALTER TABLE gdd_graph."Personagem"
ADD COLUMN description_embedding vector(384);

ALTER TABLE gdd_graph."Faccao"
ADD COLUMN description_embedding vector(384);

-- ... repetir para 13 labels restantes

-- √çndice HNSW para Stage 2 (mesmos par√¢metros do √≠ndice de chunks)
CREATE INDEX ON gdd_graph."Personagem"
USING hnsw (description_embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 100);

CREATE INDEX ON gdd_graph."Faccao"
USING hnsw (description_embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 100);

-- ... repetir para 13 labels restantes
```

**Justificativa:**
- ‚úÖ **Single query performance** - UNION ALL √© mais r√°pido que 15 queries separadas
- ‚úÖ **Embedding pr√©-computado** elimina lat√™ncia de API no Stage 2 (~500ms de chamada HuggingFace)
- ‚úÖ **Alinhado ao doc Grafo** (linha 1295): `extractRelevantSubgraph` j√° mencionado

**Refer√™ncia ao Contexto Original:**
> *"Extra√ß√£o de subgrafo implementada."* (doc Stack RAG, linha 1286)

---

#### **3.2 TypeScript Types + Agtype Parsing com Zod**

**Gap Esclarecido:** *"Documento Grafo mostra interface PersonagemProperties mas n√£o define como gerar types para todas as 15 labels nem valida√ß√£o runtime."*

**Decis√£o:** Manual types + runtime validation via Zod - escrever manualmente interfaces para as 15 labels, validar agtype parsing com Zod schemas

**Implementa√ß√£o:**

```typescript
// src/modules/gdd-rag/types/graph.types.ts
import { z } from 'zod';

// Base types
export const AgtypeVertexSchema = z.object({
  id: z.string(),
  label: z.string(),
  properties: z.record(z.any()),
});

export type AgtypeVertex<T> = {
  id: string;
  label: string;
  properties: T;
};

// ========================================
// Personagem (14 properties)
// ========================================
export const PersonagemPropertiesSchema = z.object({
  id: z.string(),
  nome: z.string(),
  nome_completo: z.string(),
  papel_narrativo: z.enum(['protagonista', 'antagonista', 'aliado', 'mentor', 'npc']),
  raca: z.string(),
  faixa_etaria: z.enum(['jovem', 'maduro', 'veterano']),
  arquetipo: z.string(),
  valores_centrais: z.array(z.string()),
  motivacao_raiz: z.string(),
  medo_fundamental: z.string().optional(),
  virtude_principal: z.string().optional(),
  fraqueza_principal: z.string().optional(),
  maior_sonho: z.string().optional(),
  jogavel: z.boolean().default(false),
  esta_vivo: z.boolean().default(true),
  status_social: z.string().optional(),
});

export type PersonagemProperties = z.infer<typeof PersonagemPropertiesSchema>;

// ========================================
// Faccao (5 properties)
// ========================================
export const FaccaoPropertiesSchema = z.object({
  id: z.string(),
  nome: z.string(),
  tipo: z.string(),
  ideologia: z.string(),
  poder_influencia: z.string(),
  lider_id: z.string().optional(),
});

export type FaccaoProperties = z.infer<typeof FaccaoPropertiesSchema>;

// ========================================
// Local (7 properties)
// ========================================
export const LocalPropertiesSchema = z.object({
  id: z.string(),
  nome: z.string(),
  tipo: z.string(),
  nivel_perigo: z.string(),
  nivel_recomendado: z.number().optional(),
  clima: z.string().optional(),
  descricao: z.string(),
  conexoes: z.array(z.string()).optional(),
});

export type LocalProperties = z.infer<typeof LocalPropertiesSchema>;

// ... repetir para 12 labels restantes

// ========================================
// Parser gen√©rico com valida√ß√£o
// ========================================
export function parseVertex<T>(
  agtypeString: string,
  schema: z.ZodSchema<T>
): AgtypeVertex<T> {
  // Remove suffix ::vertex ou ::edge
  const cleaned = agtypeString.replace(/::vertex|::edge/g, '');

  // Parse JSON
  const parsed = JSON.parse(cleaned);

  // Valida schema com Zod (throws ZodError se inv√°lido)
  const validatedProperties = schema.parse(parsed.properties);

  return {
    id: parsed.id,
    label: parsed.label,
    properties: validatedProperties,
  };
}

// ========================================
// Uso no Repository
// ========================================
// src/modules/gdd-rag/repositories/graph.repository.ts
import { Injectable, Inject } from '@nestjs/common';
import { Pool } from 'pg';
import {
  parseVertex,
  PersonagemPropertiesSchema,
  PersonagemProperties,
  AgtypeVertex
} from '../types/graph.types';

@Injectable()
export class GraphRepository {
  constructor(@Inject('PG_POOL') private pool: Pool) {}

  async findPersonagemById(id: string): Promise<AgtypeVertex<PersonagemProperties>> {
    const result = await this.pool.query(
      `SELECT * FROM cypher('gdd_graph', $$
        MATCH (p:Personagem {id: $1})
        RETURN p
      $$) as (personagem agtype)`,
      [id]
    );

    if (result.rows.length === 0) {
      throw new Error(`Personagem ${id} not found`);
    }

    // parseVertex valida schema e retorna type-safe object
    return parseVertex(result.rows[0].personagem, PersonagemPropertiesSchema);
  }
}
```

**Instala√ß√£o Zod:**
```bash
npm install zod
```

**Justificativa:**
- ‚úÖ **Type-safety completo** - autocomplete no IDE para todas as properties, detec√ß√£o de erros em compile-time
- ‚úÖ **Runtime validation** - Zod garante que agtype retornado do Postgres tem schema esperado
- ‚úÖ **Manuten√ß√£o vi√°vel** - 15 interfaces √ó ~30 linhas = ~450 linhas totais
- ‚úÖ **Zod features** - `.optional()` para nullable, `.default()` para valores padr√£o, `.enum()` para valores restritos

**Refer√™ncia ao Contexto Original:**
> *"O mapeamento desses registros para objetos TypeScript requer um parser que entenda as strings de retorno do AGE."* (doc Grafo, linhas 69-70)

---

#### **3.3 Prompt Concreto de Extra√ß√£o de Entidades**

**Gap Esclarecido:** *"Documento Grafo mostra estrutura geral do prompt mas n√£o define par√¢metros cr√≠ticos (temperatura, max_tokens, estrat√©gia de divis√£o)."*

**Decis√£o:** temperature=0.1 (baixa criatividade), max_tokens=4000 (output grande), divis√£o inteligente de se√ß√µes >15k tokens em chunks de ~10k mantendo sub-se√ß√µes completas

**Implementa√ß√£o:**

```typescript
// src/modules/gdd-rag/services/llm.service.ts
import Anthropic from '@anthropic-ai/sdk';
import { Injectable } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';

interface ExtractedData {
  entities: Array<{
    label: string;
    properties: Record<string, any>;
  }>;
  edges: Array<{
    type: string;
    source_id: string;
    target_id: string;
    properties?: Record<string, any>;
  }>;
}

@Injectable()
export class LlmService {
  private anthropic: Anthropic;

  constructor(private configService: ConfigService) {
    this.anthropic = new Anthropic({
      apiKey: this.configService.get<string>('ANTHROPIC_API_KEY'),
    });
  }

  async extractPhase1Entities(sectionText: string): Promise<ExtractedData> {
    // Dividir se necess√°rio (manter sub-se√ß√µes juntas)
    const MAX_CHUNK_SIZE = 15000; // tokens (~60k characters)
    const chunks = this.smartSplit(sectionText, MAX_CHUNK_SIZE);

    const allExtracted: ExtractedData = { entities: [], edges: [] };

    for (const chunk of chunks) {
      const prompt = `Analise esta se√ß√£o do GDD e extraia APENAS entidades narrativas.

IMPORTANTE: Retorne APENAS JSON v√°lido, sem explica√ß√µes adicionais.

LABELS A EXTRAIR (Fase 1):
- Personagem (14 properties: id, nome, nome_completo, papel_narrativo, raca, faixa_etaria, arquetipo, valores_centrais, motivacao_raiz, medo_fundamental, virtude_principal, fraqueza_principal, maior_sonho, jogavel, esta_vivo, status_social)
- Faccao (5 properties: id, nome, tipo, ideologia, poder_influencia, lider_id)
- Local (7 properties: id, nome, tipo, nivel_perigo, nivel_recomendado, clima, descricao, conexoes)
- Evento (6 properties: id, nome, ato, descricao, consequencias, gravidade, irreversivel)
- Lore (4 properties: id, nome, descricao, categoria)
- Tema (4 properties: id, nome, descricao, categoria, personagens_principais)
- ArcoPersonagem (8 properties: id, personagem_id, ato, titulo_arco, emocao_predominante, objetivo_imediato, arquetipo_fase, gatilho_mudanca, contradicoes_internas)

ARESTAS A EXTRAIR:
- PERTENCE_A (properties: cargo, desde_ato, ate_ato)
- LOCALIZADO_EM
- FILHO_DE
- PRECEDE
- MOTIVA (properties: natureza, descricao)
- TRANSFORMA (properties: natureza)
- INCORPORA (properties: intensidade)
- RELACIONA_COM (properties: tipo, subtipo, evolui_por_ato, descricao, ato_inicio, ato_fim)

Se√ß√£o do GDD:
${chunk}

Retorne JSON no formato:
{
  "entities": [
    {"label": "Personagem", "properties": {"id": "p001", "nome": "Kael", "nome_completo": "Kael Sombravento", ...}},
    ...
  ],
  "edges": [
    {"type": "PERTENCE_A", "source_id": "p001", "target_id": "f001", "properties": {"cargo": "exilado", "desde_ato": 1}},
    ...
  ]
}`;

      const response = await this.anthropic.messages.create({
        model: 'claude-3-5-sonnet-20241022',
        max_tokens: 4000, // Permite 20-30 entidades por chamada
        temperature: 0.1, // Baixa criatividade, alta precis√£o
        messages: [{ role: 'user', content: prompt }]
      });

      try {
        const extracted = JSON.parse(response.content[0].text);
        allExtracted.entities.push(...extracted.entities);
        allExtracted.edges.push(...extracted.edges);
      } catch (error) {
        console.error('Failed to parse LLM response:', error);
        console.error('Raw response:', response.content[0].text);
        // Continue processando pr√≥ximo chunk
      }
    }

    return allExtracted;
  }

  // Divis√£o inteligente preservando sub-se√ß√µes completas
  private smartSplit(text: string, maxSize: number): string[] {
    // Split em headers H2 (## )
    const sections = text.split(/\n##\s+/);
    const chunks: string[] = [];
    let currentChunk = '';

    for (const section of sections) {
      const potentialChunk = currentChunk
        ? currentChunk + '\n## ' + section
        : section;

      if (potentialChunk.length > maxSize) {
        // Flush chunk atual
        if (currentChunk) {
          chunks.push(currentChunk);
        }
        // Come√ßar novo chunk com esta se√ß√£o
        currentChunk = section;
      } else {
        currentChunk = potentialChunk;
      }
    }

    // Flush √∫ltimo chunk
    if (currentChunk) {
      chunks.push(currentChunk);
    }

    return chunks.length > 0 ? chunks : [text];
  }
}
```

**Justificativa:**
- ‚úÖ **temperature=0.1** minimiza alucina√ß√£o (cr√≠tico para extrair nomes/properties corretos)
- ‚úÖ **max_tokens=4000** permite extrair 20-30 entidades + rela√ß√µes em uma chamada
- ‚úÖ **Divis√£o inteligente** preserva contexto narrativo (biografia completa de personagem)
- ‚úÖ **Alinhado ao doc Grafo** (linhas 598-599): mesmos par√¢metros mencionados

**Custo estimado (por fase):**
- 3 chamadas √ó ~15k tokens input √ó ~4k tokens output = ~60k tokens totais
- Claude 3.5 Sonnet: ~$0.18 por fase (dentro do limite do plano Pro)

**Refer√™ncia ao Contexto Original:**
> *"O processo envolve a identifica√ß√£o de 'piv√¥s' ‚Äî n√≥s de entrada altamente relevantes."* (doc Stack RAG, linhas 28-29)

---

### RODADA 4: Opera√ß√£o e Valida√ß√£o

#### **4.1 Gatilhos de Manuten√ß√£o: Reactive Triggers**

**Gap Esclarecido:** *"Documentos recomendam VACUUM/REINDEX mas n√£o especificam quando executar nem como detectar degrada√ß√£o."*

**Decis√£o:** Reactive triggers (adequado para MVP com usu√°rio √∫nico) - executar manuten√ß√£o apenas quando perceber lentid√£o

**Ajuste de contexto:**
- **MVP com usu√°rio √∫nico** (voc√™) - n√£o precisa monitoramento proativo
- **Voc√™ √© o sensor** - detecta lentid√£o imediatamente quando queries >1-2s

**Comandos sob demanda:**
```bash
# Quando perceber lentid√£o geral
psql -U sentinel -d sentinel_gdd -c "VACUUM ANALYZE;"

# Se VACUUM n√£o resolver, tentar REINDEX
psql -U sentinel -d sentinel_gdd -c "REINDEX DATABASE sentinel_gdd;"

# REINDEX espec√≠fico (se souber qual √≠ndice)
psql -U sentinel -d sentinel_gdd -c "REINDEX INDEX gdd_chunks_embedding_idx;"
```

**Migra√ß√£o futura (quando adicionar mais usu√°rios):**
- Implementar threshold-based triggers com script `check-health.sh`
- Monitorar cache hit ratio, dead tuples, bloat ratio
- Executar semanalmente ou via cron job

**Justificativa:**
- ‚úÖ **Simplicidade m√°xima** - zero overhead de monitoramento
- ‚úÖ **Adequado para MVP** - usu√°rio √∫nico detecta problemas imediatamente
- ‚úÖ **Evolu√ß√£o clara** - migrar para threshold-based quando necess√°rio

**Refer√™ncia ao Contexto Original:**
> *"Recomenda-se a implementa√ß√£o de tarefas de manuten√ß√£o (VACUUM e REINDEX) programadas."* (doc Busca H√≠brida, linha 188)

**Esclarecimento:** Tarefas programadas s√£o para **produ√ß√£o com m√∫ltiplos usu√°rios**. MVP com usu√°rio √∫nico usa reactive approach.

---

#### **4.2 Valida√ß√£o P√≥s-Ingest√£o: Spot-Check Validation**

**Gap Esclarecido:** *"Documento Grafo menciona 'valida√ß√£o manual do JSON' mas n√£o define como verificar qualidade do grafo ap√≥s ingest√£o."*

**Decis√£o:** Spot-check validation - escolher aleatoriamente 5-10 entidades que voc√™ conhece bem do GDD, verificar se properties foram extra√≠das corretamente, extrapolar qualidade

**Script de valida√ß√£o:**

```bash
#!/bin/bash
# scripts/validate-graph.sh

echo "üîç Valida√ß√£o P√≥s-Ingest√£o do Grafo"
echo ""

# 1. Contagens b√°sicas
echo "üìä Contagens:"
psql -U sentinel -d sentinel_gdd << EOF
SELECT 'Personagem' as label, COUNT(*) as total
FROM cypher('gdd_graph', \$\$ MATCH (n:Personagem) RETURN n \$\$) as (v agtype)
UNION ALL
SELECT 'Faccao', COUNT(*)
FROM cypher('gdd_graph', \$\$ MATCH (n:Faccao) RETURN n \$\$) as (v agtype)
UNION ALL
SELECT 'Local', COUNT(*)
FROM cypher('gdd_graph', \$\$ MATCH (n:Local) RETURN n \$\$) as (v agtype)
UNION ALL
SELECT 'Evento', COUNT(*)
FROM cypher('gdd_graph', \$\$ MATCH (n:Evento) RETURN n \$\$) as (v agtype)
UNION ALL
SELECT 'TOTAL ARESTAS', COUNT(*)
FROM cypher('gdd_graph', \$\$ MATCH ()-[r]->() RETURN r \$\$) as (e agtype);
EOF

echo ""
echo "üéØ Spot Check Manual:"
echo ""

# Listar personagens principais para spot-check
echo "Personagens principais extra√≠dos:"
psql -U sentinel -d sentinel_gdd -c "
SELECT properties->>'nome' as nome,
       properties->>'papel_narrativo' as papel,
       properties->>'motivacao_raiz' as motivacao
FROM gdd_graph.\"Personagem\"
WHERE properties->>'papel_narrativo' IN ('protagonista', 'antagonista')
ORDER BY properties->>'nome';
"

echo ""
echo "Fac√ß√µes extra√≠das:"
psql -U sentinel -d sentinel_gdd -c "
SELECT properties->>'nome' as nome,
       properties->>'tipo' as tipo,
       properties->>'ideologia' as ideologia
FROM gdd_graph.\"Faccao\"
ORDER BY properties->>'nome'
LIMIT 5;
"

echo ""
echo "‚úÖ A√á√ÉO: Revise manualmente se essas entidades t√™m:"
echo "   - Nome correto"
echo "   - Papel/tipo correto"
echo "   - Motiva√ß√£o/ideologia faz sentido"
echo ""
echo "üìè Regra de qualidade:"
echo "   - Se 8 de 10 est√£o corretos ‚Üí qualidade ~80% (aceit√°vel para MVP)"
echo "   - Se <5 de 10 est√£o corretos ‚Üí revisar prompt de extra√ß√£o"
```

**Entidades cr√≠ticas para spot-check:**
1. **Personagens principais** (protagonista, antagonista) - voc√™ conhece biografias
2. **Fac√ß√µes principais** - ideologia deve estar correta
3. **Eventos marcantes** - consequ√™ncias devem fazer sentido
4. **Rela√ß√µes chave** - verificar se Kael TEM_RELACIONAMENTO(Rivalidade) Fac√ß√£o X existe

**Justificativa:**
- ‚úÖ **Efici√™ncia** - 5-10 minutos de valida√ß√£o focada vs 1-2 horas de valida√ß√£o exaustiva
- ‚úÖ **Voc√™ conhece o GDD** - sabe exatamente quais entidades s√£o cr√≠ticas
- ‚úÖ **Amostragem representativa** - se 8/10 corretos, extrapola√ß√£o ~80% qualidade geral
- ‚úÖ **Adequado para MVP** - valida√ß√£o exaustiva √© overkill, voc√™ vai iterar no GDD mesmo

**Refer√™ncia ao Contexto Original:**
> *"Valida√ß√£o manual ‚Üí Popular banco."* (doc Grafo, linha 635)

---

## üîç Gaps Resolvidos (Tabela Consolidada)

| # | **Gap Original** | **Trecho Documento** | **Decis√£o Tomada** | **Rodada** |
|---|------------------|----------------------|-------------------|------------|
| 1 | Ordem de execu√ß√£o do pipeline RAG | Stack RAG linha 573 (prompt h√≠brido n√£o detalhado) | Query ‚Üí Embedding ‚Üí Busca H√≠brida (pgvector + ts_rank_cd + RRF) ‚Üí Extra√ß√£o Subgrafo 2 est√°gios ‚Üí Prompt h√≠brido ‚Üí Claude | R1 P1 |
| 2 | Como extrair subgrafo relevante dos chunks | Stack RAG linha 1286 (extractRelevantSubgraph mencionado) | Stage 1: FTS em properties (GIN, top-5/chunk, 85-95% precis√£o, ~100-200ms) + Stage 2: embedding matching fallback (<3 entidades, +15-20% recall, +50-100ms) | R1 P2 |
| 3 | BM25 vs ts_rank | Busca H√≠brida linhas 12-13 (duas op√ß√µes, sem decis√£o) | ts_rank_cd nativo (simplicidade MVP, sem extens√µes) | R1 P3 |
| 4 | Formato metadados grafo no prompt LLM | Stack RAG linhas 573-596 (exemplo b√°sico) | Compact format: top-10 entidades (2-3 properties essenciais) + top-15 rela√ß√µes, ~1.5k tokens, texto natural | R1 P4 |
| 5 | Valores HNSW concretos | Busca H√≠brida linhas 72-78 (intervalos, n√£o valores) | Baseline conservador: m=16, ef_construction=100, ef_search=40 (~200-300MB RAM, recall 85-90%, lat√™ncia <50ms) | R2 P1 |
| 6 | Field weighting em GDD estruturado por se√ß√µes | Busca H√≠brida linhas 49-63 (n√£o espec√≠fico para se√ß√µes Markdown) | Section-based: peso A para section_name, peso B para chunk_text (coluna gerada search_vector) | R2 P2 |
| 7 | Dicion√°rio sin√¥nimos espec√≠fico do Daratrine | Busca H√≠brida linhas 32-47 (exemplos gen√©ricos TI) | 10-20 termos essenciais m√≠nimos (varia√ß√µes nomes fac√ß√µes/locais/personagens) - definir durante implementa√ß√£o | R2 P3 |
| 8 | Implementa√ß√£o Stage 1+2 de extra√ß√£o de subgrafo | Grafo linhas 136-168 (Repository Pattern sem extra√ß√£o) | Single query UNION ALL (FTS), embeddings pr√©-computados em coluna description_embedding (√≠ndice HNSW m=16), deduplicate + top-10 + top-15 rela√ß√µes 1-hop | R3 P1 |
| 9 | TypeScript types + agtype parsing para 15 labels | Grafo linhas 113-166 (exemplo Personagem, n√£o todas labels) | Manual types + Zod valida√ß√£o runtime (15 interfaces, parser parseVertex<T>() com schema validation) | R3 P2 |
| 10 | Prompt extra√ß√£o concreto (temperatura, max_tokens, divis√£o) | Grafo linhas 556-606 (estrutura geral, sem par√¢metros) | temperature=0.1, max_tokens=4000, divis√£o inteligente ~10k tokens preservando sub-se√ß√µes (split em headers H2) | R3 P3 |
| 11 | Gatilhos manuten√ß√£o VACUUM/REINDEX | Grafo linha 849 (manual on-demand, sem gatilhos) | Reactive triggers (MVP usu√°rio √∫nico) - executar quando perceber lentid√£o (queries >1-2s), migrar para threshold-based quando adicionar usu√°rios | R4 P1 |
| 12 | Valida√ß√£o qualidade grafo ap√≥s ingest√£o | Grafo linha 633 (valida√ß√£o manual JSON, sem detalhes) | Spot-check validation (5-10 entidades cr√≠ticas que voc√™ conhece bem, extrapolar ~80% se 8/10 corretos) | R4 P2 |

---

## üìö Trechos Esclarecidos do Contexto Original

### **1. Pipeline de Recupera√ß√£o em M√∫ltiplos Est√°gios**

**Trecho Original (doc Busca H√≠brida, linhas 32-34):**
> *"A precis√£o sem√¢ntica em 2026 √© alcan√ßada atrav√©s de um pipeline de recupera√ß√£o em m√∫ltiplos est√°gios. O primeiro est√°gio foca em recall (abrang√™ncia), utilizando buscas h√≠bridas que combinam vetores densos (para significado sem√¢ntico) e vetores esparsos como BM25 (para precis√£o de palavras-chave t√©cnicas e nomes pr√≥prios)."*

**Esclarecimento:**
- **Implementa√ß√£o concreta:** Busca H√≠brida (pgvector + ts_rank_cd + RRF) como primeiro est√°gio de recall
- **Segundo est√°gio:** Extra√ß√£o de subgrafo (FTS em properties + embedding matching) refina contexto
- **Terceiro est√°gio:** Prompt h√≠brido (chunks + metadados grafo) para LLM
- **Diferen√ßa:** Documento menciona "BM25" mas implementamos ts_rank_cd (adequado para MVP)

---

### **2. Reciprocal Rank Fusion (RRF)**

**Trecho Original (doc Busca H√≠brida, linhas 84-91):**
> *"O desafio fundamental da busca h√≠brida √© combinar pontua√ß√µes de relev√¢ncia de escalas incompat√≠veis: o BM25 produz valores ilimitados, enquanto a similaridade de cosseno do pgvector varia entre -1 e 1. O Reciprocal Rank Fusion (RRF) resolve esta inconsist√™ncia ignorando as pontua√ß√µes brutas e focando exclusivamente na posi√ß√£o (rank) de cada documento nas listas de resultados."*

**Esclarecimento:**
- **Implementa√ß√£o:** Mesma l√≥gica de RRF, mas com ts_rank_cd (valores ilimitados) + cosine similarity (0-1)
- **Constante k=60:** Padr√£o mencionado no documento, usada na implementa√ß√£o
- **F√≥rmula:** `score(doc) = 1/(60 + rank_vetorial) + 1/(60 + rank_fts)`

**Implementa√ß√£o TypeScript:**
```typescript
// src/modules/gdd-rag/services/search.service.ts
function reciprocalRankFusion(
  vectorResults: any[],
  ftsResults: any[],
  k: number = 60
): any[] {
  const scores = new Map<string, number>();

  // Adicionar scores vetoriais
  vectorResults.forEach((doc, index) => {
    const rank = index + 1;
    scores.set(doc.id, (scores.get(doc.id) || 0) + 1 / (k + rank));
  });

  // Adicionar scores FTS
  ftsResults.forEach((doc, index) => {
    const rank = index + 1;
    scores.set(doc.id, (scores.get(doc.id) || 0) + 1 / (k + rank));
  });

  // Ordenar por score final e retornar top-10
  return Array.from(scores.entries())
    .sort((a, b) => b[1] - a[1])
    .slice(0, 10)
    .map(([id, score]) => ({ id, score }));
}
```

---

### **3. Chunking Sem√¢ntico e Continuidade Contextual**

**Trecho Original (doc Busca H√≠brida, linhas 122-136):**
> *"A fragmenta√ß√£o (chunking) do texto √© um passo pr√©vio √† indexa√ß√£o que determina o contexto at√¥mico recuperado pelo sistema. Estrat√©gias ing√™nuas, como divis√µes por n√∫mero fixo de caracteres, frequentemente quebram a coes√£o de par√°grafos t√©cnicos ou separam defini√ß√µes de seus termos. O chunking sem√¢ntico utiliza o significado do texto para identificar pontos naturais de ruptura."*

**Esclarecimento:**
- **Estrat√©gia adotada:** Chunking por estrutura l√≥gica (headers Markdown) - doc Stack RAG linha 159
- **Divis√£o inteligente na extra√ß√£o:** Preserve sub-se√ß√µes completas (~10k tokens) ao dividir se√ß√µes grandes
- **Field weighting:** Section-based (peso A para section_name, peso B para chunk_text) aproveita estrutura
- **Alinhamento:** Chunking sem√¢ntico do documento + field weighting = m√°xima preserva√ß√£o de contexto

---

### **4. Par√¢metros HNSW e Trade-offs**

**Trecho Original (doc Busca H√≠brida, linhas 72-80):**
> *"A constru√ß√£o do √≠ndice HNSW √© influenciada por par√¢metros que determinam a densidade das conex√µes no grafo multicamada. O par√¢metro m define o n√∫mero m√°ximo de conex√µes por n√≥, enquanto o ef_construction controla o tamanho da lista de candidatos durante a fase de cria√ß√£o do √≠ndice. Para um MVP RAG, valores equilibrados s√£o fundamentais."*

**Esclarecimento:**
- **Decis√£o:** Baseline conservador (m=16, ef_construction=100, ef_search=40) priorizando **uso de RAM**
- **Trade-off aceito:** Recall ~85-90% (vs ~95-98% com m=32) em troca de RAM controlada (~200-300MB vs ~600-800MB)
- **Justificativa:** Para ~2.4k chunks do MVP, diferen√ßa de recall √© marginal mas economia de RAM √© significativa
- **Escalabilidade:** Se ultrapassar 10k chunks, aumentar para m=24 via REINDEX

---

### **5. GraphRAG e Travessia do Grafo**

**Trecho Original (doc Stack RAG, linhas 25-30):**
> *"O GraphRAG surge como a t√©cnica dominante em 2026 para lidar com a descoberta de informa√ß√µes em dados narrativos privados e t√©cnicos. Ao contr√°rio do RAG de linha de base, que tem dificuldade em conectar pontos dispersos em grandes cole√ß√µes de documentos, o GraphRAG utiliza LLMs para criar grafos de conhecimento que facilitam o entendimento de conceitos sem√¢nticos resumidos. O processo envolve a identifica√ß√£o de 'piv√¥s' ‚Äî n√≥s de entrada altamente relevantes ‚Äî seguida pela expans√£o da relev√¢ncia atrav√©s da travessia do grafo."*

**Esclarecimento:**
- **Piv√¥s:** Entidades identificadas via Stage 1 (FTS) + Stage 2 (embedding matching) nos chunks
- **Travessia:** Busca de rela√ß√µes 1-hop (limitado para efici√™ncia) - `MATCH (source)-[r]->(target) WHERE source.id IN [pivots]`
- **Limita√ß√£o:** 1-hop √© suficiente para prompt LLM (top-10 entidades + top-15 rela√ß√µes = ~1.5k tokens)
- **Expans√£o futura:** Implementar travessia multi-hop (2-3 saltos) se necess√°rio ap√≥s validar MVP

---

### **6. Configura√ß√£o Avan√ßada do Motor de Busca em Portugu√™s**

**Trecho Original (doc Busca H√≠brida, linhas 27-48):**
> *"Para um MVP robusto, a configura√ß√£o padr√£o do PostgreSQL para o portugu√™s pode ser insuficiente, especialmente ao lidar com termos t√©cnicos anglicizados comuns na √°rea de TI. A implementa√ß√£o exige a cria√ß√£o de uma configura√ß√£o de busca personalizada que integre o m√≥dulo unaccent para remover sensibilidade a diacr√≠ticos e dicion√°rios de sin√¥nimos para padronizar siglas t√©cnicas."*

**Esclarecimento:**
- **Implementa√ß√£o concreta:**
  1. **unaccent:** `to_tsvector('portuguese', unaccent(text))` - remove acentos
  2. **Dicion√°rio sin√¥nimos:** `tech_synonyms.syn` com 10-20 termos do Daratrine
  3. **Text search configuration customizada:** `daratrine_pt` (c√≥pia de `portuguese` + sin√¥nimos)
- **Ordem de preced√™ncia:** Sin√¥nimos ‚Üí unaccent ‚Üí stemmer portugu√™s (Snowball)
- **Definir durante implementa√ß√£o:** Termos espec√≠ficos ser√£o extra√≠dos do GDD real

---

## üöÄ Pr√≥ximos Passos de Implementa√ß√£o

### **Semana 1-2: Setup + Configura√ß√£o PostgreSQL**

**Milestone:** Ambiente completo com pgvector + Apache AGE + FTS configurado

**Tarefas:**

1. **Docker Compose com Postgres Custom**
   ```bash
   # Criar Dockerfile custom (Postgres 16 + AGE + pgvector)
   # J√° documentado no doc Stack RAG linha 643-666
   cd sentinel
   docker-compose up -d postgres
   ```

2. **Executar init.sql**
   ```sql
   -- Habilitar extens√µes
   CREATE EXTENSION IF NOT EXISTS vector;
   CREATE EXTENSION IF NOT EXISTS age;
   CREATE EXTENSION IF NOT EXISTS unaccent;
   CREATE EXTENSION IF NOT EXISTS pg_trgm;

   -- Criar schema AGE
   SELECT create_graph('gdd_graph');

   -- Criar tabela de chunks com busca h√≠brida
   CREATE TABLE gdd_chunks (
       id SERIAL PRIMARY KEY,
       section_name TEXT NOT NULL,
       section_level INT,
       chunk_text TEXT NOT NULL,
       embedding vector(384), -- Sentence-Transformers dimension
       metadata JSONB,
       created_at TIMESTAMP DEFAULT NOW()
   );

   -- Adicionar coluna search_vector com field weighting
   ALTER TABLE gdd_chunks ADD COLUMN search_vector tsvector
   GENERATED ALWAYS AS (
     setweight(to_tsvector('portuguese', unaccent(coalesce(section_name, ''))), 'A') ||
     setweight(to_tsvector('portuguese', unaccent(coalesce(chunk_text, ''))), 'B')
   ) STORED;

   -- Criar √≠ndices
   -- HNSW para busca vetorial (baseline conservador)
   CREATE INDEX ON gdd_chunks
   USING hnsw (embedding vector_cosine_ops)
   WITH (m = 16, ef_construction = 100);

   -- Configurar ef_search
   ALTER DATABASE sentinel_gdd SET hnsw.ef_search = 40;

   -- GIN para Full-Text Search
   CREATE INDEX ON gdd_chunks USING gin(search_vector);
   ```

3. **Criar configura√ß√£o de sin√¥nimos** (durante implementa√ß√£o, ap√≥s extrair GDD)
   ```bash
   # Criar arquivo tech_synonyms.syn
   # (definir termos ap√≥s ler GDD real do Daratrine)

   # Configurar text search configuration
   psql -U sentinel -d sentinel_gdd << EOF
   CREATE TEXT SEARCH CONFIGURATION daratrine_pt (COPY = portuguese);

   ALTER TEXT SEARCH CONFIGURATION daratrine_pt
     ALTER MAPPING FOR asciiword, word
     WITH tech_synonyms, portuguese_stem;
   EOF
   ```

4. **Adicionar coluna description_embedding nas 15 labels do grafo**
   ```sql
   -- Executar durante Fase 1-3 da implementa√ß√£o do grafo
   ALTER TABLE gdd_graph."Personagem" ADD COLUMN description_embedding vector(384);
   ALTER TABLE gdd_graph."Faccao" ADD COLUMN description_embedding vector(384);
   -- ... repetir para 13 labels restantes

   -- Criar √≠ndices HNSW (mesmos par√¢metros)
   CREATE INDEX ON gdd_graph."Personagem"
   USING hnsw (description_embedding vector_cosine_ops)
   WITH (m = 16, ef_construction = 100);
   -- ... repetir para 13 labels restantes
   ```

**Crit√©rios de Sucesso:**
- ‚úÖ Docker Compose sobe Postgres 16 com AGE + pgvector + unaccent
- ‚úÖ Extens√µes habilitadas e funcionando
- ‚úÖ √çndices criados (HNSW m=16, GIN)
- ‚úÖ Coluna search_vector com field weighting (peso A/B) funcionando

---

### **Semana 2-3: Implementa√ß√£o NestJS - GraphService + SearchService**

**Milestone:** Stage 1+2 de extra√ß√£o de subgrafo funcionando

**Tarefas:**

1. **Instalar depend√™ncias**
   ```bash
   npm install zod
   npm install @anthropic-ai/sdk
   # pg j√° instalado (TypeORM/Prisma)
   ```

2. **Criar TypeScript types com Zod**
   ```bash
   # Criar arquivo types/graph.types.ts
   # Implementar 15 interfaces + schemas Zod
   # (c√≥digo completo na se√ß√£o 3.2)
   ```

3. **Implementar GraphService**
   ```typescript
   // src/modules/gdd-rag/services/graph.service.ts
   // Implementar extractRelevantSubgraph com Stage 1+2
   // (c√≥digo completo na se√ß√£o 3.1)
   ```

4. **Implementar SearchService**
   ```typescript
   // src/modules/gdd-rag/services/search.service.ts
   @Injectable()
   export class SearchService {
     async hybridSearch(query: string): Promise<Chunk[]> {
       // 1. Gerar embedding
       const embedding = await this.embeddingService.generate(query);

       // 2. Busca vetorial
       const vectorResults = await this.vectorSearch(embedding, 20);

       // 3. Busca FTS
       const ftsResults = await this.ftsSearch(query, 20);

       // 4. RRF
       const merged = this.reciprocalRankFusion(vectorResults, ftsResults);

       // 5. Retornar top-10 chunks
       return merged.slice(0, 10);
     }

     private async vectorSearch(embedding: number[], limit: number) {
       const result = await this.pool.query(
         `SELECT id, chunk_text, 1 - (embedding <=> $1::vector) AS similarity
          FROM gdd_chunks
          ORDER BY embedding <=> $1::vector
          LIMIT $2`,
         [embedding, limit]
       );
       return result.rows;
     }

     private async ftsSearch(query: string, limit: number) {
       const result = await this.pool.query(
         `SELECT id, chunk_text,
                 ts_rank_cd(search_vector, plainto_tsquery('portuguese', $1)) AS rank
          FROM gdd_chunks
          WHERE search_vector @@ plainto_tsquery('portuguese', $1)
          ORDER BY rank DESC
          LIMIT $2`,
         [query, limit]
       );
       return result.rows;
     }

     private reciprocalRankFusion(vectorResults: any[], ftsResults: any[], k: number = 60) {
       // Implementa√ß√£o RRF (c√≥digo na se√ß√£o "Trechos Esclarecidos")
     }
   }
   ```

5. **Testar Stage 1+2 isoladamente**
   ```bash
   # Criar script de teste
   npm run test:graph-service
   ```

**Crit√©rios de Sucesso:**
- ‚úÖ GraphService.extractRelevantSubgraph retorna top-10 entidades + top-15 rela√ß√µes
- ‚úÖ Stage 1 (FTS) funciona em ~100-200ms
- ‚úÖ Stage 2 (embedding matching) s√≥ roda quando <3 entidades
- ‚úÖ Zod validation captura erros de schema

---

### **Semana 3: Integra√ß√£o RagService + LlmService**

**Milestone:** Pipeline RAG completo end-to-end funcionando

**Tarefas:**

1. **Implementar LlmService**
   ```typescript
   // src/modules/gdd-rag/services/llm.service.ts
   // (c√≥digo completo na se√ß√£o 3.3)
   ```

2. **Implementar RagService (orquestra√ß√£o)**
   ```typescript
   // src/modules/gdd-rag/services/rag.service.ts
   @Injectable()
   export class RagService {
     constructor(
       private embeddingService: EmbeddingService,
       private searchService: SearchService,
       private graphService: GraphService,
       private llmService: LlmService,
     ) {}

     async processQuery(query: string): Promise<string> {
       // 1. Busca H√≠brida
       const chunks = await this.searchService.hybridSearch(query);

       // 2. Extra√ß√£o de Subgrafo
       const graphMetadata = await this.graphService.extractRelevantSubgraph(chunks);

       // 3. Montar Prompt H√≠brido
       const prompt = this.buildHybridPrompt(query, chunks, graphMetadata);

       // 4. LLM Response
       return await this.llmService.generateResponse(prompt);
     }

     private buildHybridPrompt(query: string, chunks: Chunk[], graphMetadata: GraphMetadata): string {
       const SYSTEM_PROMPT = `Voc√™ √© um assistente especializado em GDD de RPG.

       REGRAS:
       1. Responda APENAS baseado no contexto fornecido
       2. Se informa√ß√£o n√£o estiver no contexto: "N√£o encontrei essa informa√ß√£o no GDD"
       3. NUNCA invente nomes/eventos/lore
       4. Mencione contradi√ß√µes se houver
       5. Respostas concisas (m√°ximo 3-4 par√°grafos)`;

       const graphMetadataText = this.formatGraphMetadata(graphMetadata);
       const chunksText = chunks.map((c, i) => `[Chunk ${i+1}] ${c.section_name}\n${c.text}`).join('\n---\n');

       return `${SYSTEM_PROMPT}

===== KNOWLEDGE GRAPH METADATA =====
${graphMetadataText}

===== TEXT CHUNKS FROM GDD =====
${chunksText}

===== USER QUERY =====
${query}

Responda usando APENAS o contexto acima.`;
     }

     private formatGraphMetadata(metadata: GraphMetadata): string {
       const entitiesText = metadata.entities.map(e => {
         // Extrair 2-3 properties essenciais baseado no label
         const essentialProps = this.getEssentialProperties(e);
         return `- ${e.label}: ${essentialProps.nome} (${essentialProps.descricao})`;
       }).join('\n');

       const relationsText = metadata.relations.map(r => {
         return `- ${r.source_name} ${r.type} ${r.target_name}`;
       }).join('\n');

       return `Entidades Relevantes (${metadata.entities.length}):\n${entitiesText}\n\nRela√ß√µes Relevantes (${metadata.relations.length}):\n${relationsText}`;
     }
   }
   ```

3. **Implementar Controllers REST**
   ```typescript
   // src/modules/gdd-rag/controllers/rag-query.controller.ts
   @Controller('api/rag')
   export class RagQueryController {
     constructor(private ragService: RagService) {}

     @Post('query')
     async query(@Body() body: { query: string }) {
       return { answer: await this.ragService.processQuery(body.query) };
     }
   }
   ```

4. **Testar pipeline end-to-end**
   ```bash
   # Iniciar servidor
   npm run start:dev

   # Testar via curl
   curl -X POST http://localhost:3000/api/rag/query \
     -H "Content-Type: application/json" \
     -d '{"query": "Quem √© Kael Sombravento?"}'
   ```

**Crit√©rios de Sucesso:**
- ‚úÖ Pipeline completo funciona (query ‚Üí resposta em ~2-3s)
- ‚úÖ Resposta inclui contexto do grafo (menciona rela√ß√µes)
- ‚úÖ Claude 3.5 Sonnet n√£o alucina (responde baseado no contexto)

---

### **Semana 4: Ingest√£o do GDD + Valida√ß√£o**

**Milestone:** GDD real do Daratrine ingerido e validado

**Tarefas:**

1. **Implementar script de ingest√£o**
   ```bash
   # J√° documentado no doc Grafo (scripts/ingest-phase1.ts)
   # Usar LlmService.extractPhase1Entities
   npm run script:ingest-phase1
   ```

2. **Definir dicion√°rio de sin√¥nimos durante ingest√£o**
   ```bash
   # Ao processar GDD, identificar varia√ß√µes comuns
   # Ex: "Crep√∫sculo" vs "Fac√ß√£o do Crep√∫sculo" vs "Culto Crep√∫sculo"
   # Criar tech_synonyms.syn
   ```

3. **Executar valida√ß√£o spot-check**
   ```bash
   ./scripts/validate-graph.sh

   # Revisar manualmente 5-10 entidades cr√≠ticas
   # Se 8/10 corretos ‚Üí qualidade ~80% (aceit√°vel)
   # Se <5/10 corretos ‚Üí ajustar prompt de extra√ß√£o
   ```

4. **Iterar se necess√°rio**
   - Ajustar temperature (tentar 0.05 se muita alucina√ß√£o)
   - Melhorar prompt (adicionar exemplos de entidades corretas)
   - Re-executar extra√ß√£o

**Crit√©rios de Sucesso:**
- ‚úÖ ~2.400 v√©rtices extra√≠dos
- ‚úÖ ~8.000 arestas extra√≠das
- ‚úÖ Qualidade spot-check >70% (7/10 entidades corretas)
- ‚úÖ Queries RAG retornam respostas coerentes sobre o GDD

---

## üìä Checklist de Implementa√ß√£o

### **Setup Inicial**
- [ ] Docker Compose configurado (Postgres 16 + AGE + pgvector)
- [ ] Extens√µes habilitadas (vector, age, unaccent, pg_trgm)
- [ ] Tabela gdd_chunks criada com search_vector (field weighting A/B)
- [ ] √çndices criados (HNSW m=16, GIN)
- [ ] Coluna description_embedding adicionada nas 15 labels do grafo

### **TypeScript Types**
- [ ] Zod instalado
- [ ] 15 interfaces criadas (Personagem, Fac√ß√£o, Local, etc.)
- [ ] 15 schemas Zod criados com valida√ß√£o runtime
- [ ] Parser parseVertex<T>() implementado

### **Services NestJS**
- [ ] EmbeddingService (HuggingFace API)
- [ ] SearchService (busca h√≠brida: pgvector + FTS + RRF)
- [ ] GraphService (Stage 1: FTS em properties, Stage 2: embedding matching)
- [ ] LlmService (extra√ß√£o de entidades + gera√ß√£o de respostas via Claude)
- [ ] RagService (orquestra√ß√£o do pipeline completo)

### **Controllers REST**
- [ ] POST /api/rag/query (query conversacional)
- [ ] GET /api/rag/entities (listar entidades)
- [ ] GET /api/rag/entities/:id (detalhes de entidade)

### **Ingest√£o e Valida√ß√£o**
- [ ] Script ingest-phase1.ts (extra√ß√£o via Claude 3.5 Sonnet)
- [ ] Dicion√°rio tech_synonyms.syn criado (10-20 termos Daratrine)
- [ ] Script validate-graph.sh (spot-check validation)
- [ ] GDD real ingerido (~2.4k v√©rtices, ~8k arestas)
- [ ] Valida√ß√£o spot-check >70% de qualidade

### **Testes**
- [ ] Pipeline end-to-end testado (query ‚Üí resposta em ~2-3s)
- [ ] Stage 1 (FTS) performando em ~100-200ms
- [ ] Stage 2 (embedding) s√≥ rodando quando necess√°rio
- [ ] Respostas incluem contexto do grafo (entidades + rela√ß√µes)

---

## üìà M√©tricas de Sucesso Definidas

### **MVP (Implementa√ß√£o Completa):**
- [ ] **Taxa de Sucesso de Ingest√£o:** >70% das entidades extra√≠das corretamente (valida√ß√£o spot-check)
- [ ] **Lat√™ncia Pipeline Completo:** <3s P95 (busca h√≠brida + extra√ß√£o subgrafo + LLM)
- [ ] **Lat√™ncia Busca H√≠brida:** <100ms P95 (pgvector + FTS + RRF)
- [ ] **Lat√™ncia Extra√ß√£o Subgrafo:** <300ms P95 (Stage 1 + Stage 2 condicional)
- [ ] **Recall Busca Vetorial:** 85-90% (√≠ndice HNSW m=16)
- [ ] **Recall Extra√ß√£o Subgrafo:** 85-100% (Stage 1: 70-85%, Stage 2: +15-20%)
- [ ] **Qualidade Percebida:** Voc√™ reporta "respostas √∫teis" em >70% das queries

### **P√≥s-Refinamento (Itera√ß√£o):**
- [ ] **Uso de Contexto Grafo:** >50% das respostas citam rela√ß√µes do grafo (n√£o apenas chunks)
- [ ] **Alucina√ß√£o:** <5% das queries (resposta cont√©m informa√ß√£o n√£o presente no GDD)
- [ ] **Cobertura:** >80% das queries encontram contexto relevante (n√£o retornam "n√£o encontrei")

### **Operacional:**
- [ ] **Manuten√ß√£o:** Zero overhead (reactive triggers - VACUUM/REINDEX quando voc√™ perceber lentid√£o)
- [ ] **Uso de RAM:** <1GB total (Postgres + √≠ndices HNSW + AGE)
- [ ] **Espa√ßo em Disco:** <500MB (chunks + embeddings + grafo)

---

## üîó Refer√™ncias

- **Documento Principal:** [Busca H√≠brida com pgvector e FTS.md](../pesquisas/Busca%20H√≠brida%20com%20pgvector%20e%20FTS.md)
- **Documentos Relacionados:**
  - [Decis√µes Arquiteturais - Grafos de Conhecimento com Apache AGE](decisoes-arquiteturais-grafo.md)
  - [Stack RAG Alta Fidelidade para GDDs](entrevista-stack-rag-gdd-2026-01-29.md)
- **Tecnologias Decididas:**
  - [pgvector](https://github.com/pgvector/pgvector) - Vector similarity search for PostgreSQL
  - [Apache AGE](https://age.apache.org/) - Graph extension for PostgreSQL
  - PostgreSQL 16 Full-Text Search (ts_rank_cd, GIN index, unaccent)
  - [Claude 3.5 Sonnet](https://docs.anthropic.com/en/docs/models-overview) - LLM via Anthropic API (plano Pro)
  - [Sentence-Transformers](https://www.sbert.net/) - Embedding models via HuggingFace
  - [Zod](https://zod.dev/) - TypeScript-first schema validation
  - [NestJS](https://nestjs.com/) - Backend framework

---

## üìù Conclus√£o

Este documento consolida **12 decis√µes t√©cnicas cr√≠ticas** que transformam o conhecimento estado-da-arte dos documentos de pesquisa em uma arquitetura execut√°vel para o projeto Sentinel/Daratrine.

**Princ√≠pios Norteadores:**
1. **Simplicidade Operacional:** Reactive triggers (usu√°rio √∫nico), zero overhead de monitoramento
2. **Performance Adequada:** HNSW baseline conservador (85-90% recall suficiente para MVP)
3. **Valida√ß√£o R√°pida:** Spot-check (5-10 entidades) vs valida√ß√£o exaustiva
4. **Type-Safety Completo:** Zod validation em todas as 15 labels, detec√ß√£o de erros em runtime

**Diferenciais da Abordagem:**
- **Pipeline de 2 Est√°gios:** FTS em properties (85-95% precis√£o) + embedding matching fallback (+15-20% recall) = 85-100% recall total
- **Prompt H√≠brido Compact:** Top-10 entidades (2-3 properties essenciais) + top-15 rela√ß√µes (~1.5k tokens) maximiza contexto sem explodir tokens
- **Field Weighting Section-Based:** Aproveita estrutura natural do GDD (peso A para section_name, peso B para chunk_text)
- **Infraestrutura Unificada:** Postgres √∫nico (grafos + vetores + FTS + dados relacionais), zero lock-in

O sistema est√° pronto para implementa√ß√£o. Pr√≥ximo passo: **Semana 1-2 - Setup + Configura√ß√£o PostgreSQL**.

---

**Documento gerado em:** 2026-01-30
**Autor:** Entrevista estruturada com decis√µes consensuais
**Status:** ‚úÖ Aprovado para implementa√ß√£o
